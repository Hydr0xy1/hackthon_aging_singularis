import re
import sys
import os
import json
from pathlib import Path
from typing import List, Dict, Any
from collections import Counter

# æ·»åŠ utilså¯¼å…¥
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from src.utils import CUE_PATTERNS, sentence_segmentation, gen_id

def create_node(node_type: str, text: str, section: str, confidence: float = 0.9, evidence: str = "") -> Dict[str, Any]:
    """åˆ›å»ºèŠ‚ç‚¹"""
    return {
        "id": gen_id(node_type[:3].upper()),
        "type": node_type,
        "text": text.strip(),
        "section": section,
        "confidence": confidence,
        "evidence": evidence
    }

def extract_nodes_from_section(section_name: str, text: str) -> List[Dict[str, Any]]:
    """ä»ç« èŠ‚æ–‡æœ¬æå–èŠ‚ç‚¹"""
    sentences = sentence_segmentation(text)
    nodes = []
    
    for sentence in sentences:
        matched = False
        for node_type, patterns in CUE_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, sentence, re.IGNORECASE):
                    nodes.append(create_node(
                        node_type, sentence, section_name, 
                        evidence=f"pattern:{pattern}",
                        confidence=0.85
                    ))
                    matched = True
                    break
            if matched:
                break
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ¨¡å¼ï¼Œè·³è¿‡è¯¥å¥å­
    
    return nodes

def extract_imrad_from_text(text: str) -> List[Dict[str, Any]]:
    """ä»å®Œæ•´æ–‡æœ¬æå–IMRaDèŠ‚ç‚¹ - è¿™æ˜¯ç¼ºå¤±çš„å…³é”®å‡½æ•°ï¼"""
    try:
        from src.pdf_to_text import segment_imrad
    except ImportError as e:
        print(f"å¯¼å…¥segment_imradå¤±è´¥: {e}")
        # å¤‡ç”¨åˆ†æ®µæ–¹æ³•
        def simple_segment_imrad(text):
            sections = {}
            current_section = "body"
            sections[current_section] = text
            return sections
        segment_imrad = simple_segment_imrad
    
    sections = segment_imrad(text)
    all_nodes = []
    
    print(f"ğŸ“‘ å‘ç° {len(sections)} ä¸ªç« èŠ‚: {list(sections.keys())}")
    
    for section_name, section_text in sections.items():
        if len(section_text.strip()) < 50:  # è·³è¿‡å¤ªçŸ­çš„ç« èŠ‚
            continue
            
        print(f"  å¤„ç†ç« èŠ‚: {section_name} (é•¿åº¦: {len(section_text)} å­—ç¬¦)")
        nodes = extract_nodes_from_section(section_name, section_text)
        print(f"    åœ¨ {section_name} ä¸­æå–äº† {len(nodes)} ä¸ªèŠ‚ç‚¹")
        all_nodes.extend(nodes)
    
    # ç»Ÿè®¡èŠ‚ç‚¹ç±»å‹
    if all_nodes:
        node_types = Counter([node["type"] for node in all_nodes])
        print(f"ğŸ“Š èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ: {dict(node_types)}")
    
    return all_nodes

# ä¸ºäº†å…¼å®¹æ€§ï¼Œä¹Ÿæ·»åŠ æ—§å‡½æ•°å
extract_imrad_nodes = extract_imrad_from_text

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python extract_imrad.py <text_file>")
        sys.exit(1)
    
    text_file = sys.argv[1]
    if not os.path.exists(text_file):
        print(f"Error: File {text_file} not found")
        sys.exit(1)
    
    with open(text_file, "r", encoding="utf-8") as f:
        text = f.read()
    
    nodes = extract_imrad_from_text(text)
    
    # ä¿å­˜èŠ‚ç‚¹
    output_file = text_file.replace(".txt", "_nodes.json")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(nodes, f, indent=2, ensure_ascii=False)
    
    print(f"Extracted {len(nodes)} nodes to {output_file}")