#!/usr/bin/env python3
"""
é«˜ç²¾åº¦PDFæ–‡æœ¬æå–å™¨
è§£å†³PDFæ–‡æœ¬æå–ä¸­çš„å„ç§é—®é¢˜ï¼Œæå‡ç²¾ç¡®åº¦
"""

import fitz
import re
import sys
import os
from pathlib import Path
from typing import List, Tuple, Dict, Any
import unicodedata

class EnhancedPDFExtractor:
    """é«˜ç²¾åº¦PDFæ–‡æœ¬æå–å™¨"""
    
    def __init__(self):
        # å¸¸è§PDFé—®é¢˜æ¨¡å¼
        self.problem_patterns = {
            'page_numbers': [
                r'^\s*\d+\s*$',  # çº¯æ•°å­—é¡µç 
                r'^\s*-\s*\d+\s*-\s*$',  # -1-, -2- æ ¼å¼
                r'^\s*Page\s+\d+\s*$',  # Page 1, Page 2
                r'^\s*\d+\s*of\s+\d+\s*$',  # 1 of 10
            ],
            'headers_footers': [
                r'^\s*[A-Z\s]+\s*$',  # å…¨å¤§å†™æ ‡é¢˜
                r'^\s*[A-Z][a-z]+\s+[A-Z][a-z]+\s*$',  # ä½œè€…åç­‰
                r'^\s*Â©\s*\d{4}\s*',  # ç‰ˆæƒä¿¡æ¯
                r'^\s*doi:\s*',  # DOIä¿¡æ¯
                r'^\s*http[s]?://',  # URL
            ],
            'figure_captions': [
                r'^\s*Figure\s+\d+',  # Figure 1, Figure 2
                r'^\s*Fig\.\s+\d+',  # Fig. 1
                r'^\s*Table\s+\d+',  # Table 1
                r'^\s*Tab\.\s+\d+',  # Tab. 1
            ],
            'references': [
                r'^\s*\[\d+\]',  # [1], [2]
                r'^\s*\d+\.\s*[A-Z]',  # 1. Author
            ],
            'noise_lines': [
                r'^\s*$',  # ç©ºè¡Œ
                r'^\s*\.\s*$',  # åªæœ‰ç‚¹
                r'^\s*-\s*$',  # åªæœ‰æ¨ªçº¿
                r'^\s*_\s*$',  # åªæœ‰ä¸‹åˆ’çº¿
            ]
        }
        
        # å­¦æœ¯è®ºæ–‡ç‰¹å®šæ¨¡å¼
        self.academic_patterns = {
            'sections': [
                r'^\s*\d*\.?\s*(Abstract|Introduction|Methods?|Results?|Discussion|Conclusion|References)',
                r'^\s*\d+\.\d*\s+[A-Z]',  # 1.1, 1.2 ç­‰å­ç« èŠ‚
            ],
            'citations': [
                r'\([A-Z][a-z]+\s+et\s+al\.\s*,\s*\d{4}\)',  # (Author et al., 2024)
                r'\[[A-Z][a-z]+\s+et\s+al\.\s*,\s*\d{4}\]',  # [Author et al., 2024]
            ],
            'measurements': [
                r'\d+\.\d+\s*(mg|kg|ml|Î¼l|mm|cm|Â°C|Â°F)',  # æµ‹é‡å•ä½
                r'p\s*[<â‰¤]\s*0\.\d+',  # p < 0.05
            ]
        }
    
    def extract_text_from_pdf(self, pdf_path: str, out_path: str = None) -> str:
        """é«˜ç²¾åº¦PDFæ–‡æœ¬æå–"""
        print(f"ğŸ“„ å¼€å§‹é«˜ç²¾åº¦æå–: {os.path.basename(pdf_path)}")
        
        try:
            doc = fitz.open(pdf_path)
            all_text = []
            page_stats = []
            
            for page_num, page in enumerate(doc):
                # è·å–é¡µé¢æ–‡æœ¬
                page_text = page.get_text("text")
                
                # åˆ†æé¡µé¢å†…å®¹
                page_analysis = self._analyze_page_content(page_text, page_num)
                page_stats.append(page_analysis)
                
                # æ¸…ç†å’Œä¼˜åŒ–æ–‡æœ¬
                cleaned_text = self._clean_page_text(page_text, page_analysis)
                
                if cleaned_text.strip():
                    all_text.append(cleaned_text)
            
            doc.close()
            
            # åå¤„ç†æ•´ä¸ªæ–‡æ¡£
            final_text = self._post_process_document(all_text, page_stats)
            
            # ä¿å­˜ç»“æœ
            if out_path:
                with open(out_path, "w", encoding="utf-8") as f:
                    f.write(final_text)
                print(f"âœ… é«˜ç²¾åº¦æ–‡æœ¬å·²ä¿å­˜: {out_path}")
            
            return final_text
            
        except Exception as e:
            print(f"âŒ PDFæå–é”™è¯¯: {e}")
            return ""
    
    def _analyze_page_content(self, page_text: str, page_num: int) -> Dict[str, Any]:
        """åˆ†æé¡µé¢å†…å®¹ç‰¹å¾"""
        lines = page_text.split('\n')
        
        analysis = {
            'page_num': page_num,
            'total_lines': len(lines),
            'content_lines': 0,
            'header_lines': 0,
            'footer_lines': 0,
            'figure_captions': 0,
            'references': 0,
            'noise_lines': 0,
            'avg_line_length': 0,
            'has_abstract': False,
            'has_references': False,
            'content_quality': 'unknown'
        }
        
        content_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                analysis['noise_lines'] += 1
                continue
            
            # æ£€æŸ¥å„ç§æ¨¡å¼
            is_header = self._is_header_footer(line)
            is_figure = self._is_figure_caption(line)
            is_reference = self._is_reference(line)
            is_noise = self._is_noise_line(line)
            
            if is_header:
                analysis['header_lines'] += 1
            elif is_figure:
                analysis['figure_captions'] += 1
            elif is_reference:
                analysis['references'] += 1
            elif is_noise:
                analysis['noise_lines'] += 1
            else:
                content_lines.append(line)
                analysis['content_lines'] += 1
        
        # è®¡ç®—å¹³å‡è¡Œé•¿åº¦
        if content_lines:
            analysis['avg_line_length'] = sum(len(line) for line in content_lines) / len(content_lines)
        
        # æ£€æµ‹ç‰¹æ®Šå†…å®¹
        full_text = ' '.join(content_lines).lower()
        analysis['has_abstract'] = 'abstract' in full_text
        analysis['has_references'] = 'references' in full_text or 'bibliography' in full_text
        
        # è¯„ä¼°å†…å®¹è´¨é‡
        analysis['content_quality'] = self._assess_content_quality(analysis)
        
        return analysis
    
    def _is_header_footer(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé¡µçœ‰é¡µè„š"""
        for pattern in self.problem_patterns['headers_footers']:
            if re.match(pattern, line, re.IGNORECASE):
                return True
        return False
    
    def _is_figure_caption(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå›¾è¡¨æ ‡é¢˜"""
        for pattern in self.problem_patterns['figure_captions']:
            if re.match(pattern, line, re.IGNORECASE):
                return True
        return False
    
    def _is_reference(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå‚è€ƒæ–‡çŒ®"""
        for pattern in self.problem_patterns['references']:
            if re.match(pattern, line):
                return True
        return False
    
    def _is_noise_line(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå™ªéŸ³è¡Œ"""
        for pattern in self.problem_patterns['noise_lines']:
            if re.match(pattern, line):
                return True
        return False
    
    def _assess_content_quality(self, analysis: Dict[str, Any]) -> str:
        """è¯„ä¼°é¡µé¢å†…å®¹è´¨é‡"""
        content_ratio = analysis['content_lines'] / max(analysis['total_lines'], 1)
        
        if content_ratio > 0.8:
            return 'high'
        elif content_ratio > 0.6:
            return 'medium'
        else:
            return 'low'
    
    def _clean_page_text(self, page_text: str, analysis: Dict[str, Any]) -> str:
        """æ¸…ç†é¡µé¢æ–‡æœ¬"""
        lines = page_text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œå’Œå™ªéŸ³
            if not line or self._is_noise_line(line):
                continue
            
            # è·³è¿‡é¡µçœ‰é¡µè„š
            if self._is_header_footer(line):
                continue
            
            # è·³è¿‡é¡µç 
            if re.match(r'^\s*\d+\s*$', line):
                continue
            
            # å¤„ç†å›¾è¡¨æ ‡é¢˜ï¼ˆå¯é€‰ä¿ç•™ï¼‰
            if self._is_figure_caption(line):
                # å¯¹äºå­¦æœ¯è®ºæ–‡ï¼Œå¯èƒ½æƒ³ä¿ç•™å›¾è¡¨æ ‡é¢˜
                if analysis['content_quality'] == 'high':
                    cleaned_lines.append(line)
                continue
            
            # å¤„ç†å‚è€ƒæ–‡çŒ®ï¼ˆå¯é€‰ä¿ç•™ï¼‰
            if self._is_reference(line):
                # æ ¹æ®é¡µé¢è´¨é‡å†³å®šæ˜¯å¦ä¿ç•™
                if analysis['has_references'] and analysis['content_quality'] == 'high':
                    cleaned_lines.append(line)
                continue
            
            # ä¿ç•™æœ‰æ•ˆå†…å®¹
            if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _post_process_document(self, all_text: List[str], page_stats: List[Dict[str, Any]]) -> str:
        """åå¤„ç†æ•´ä¸ªæ–‡æ¡£"""
        # åˆå¹¶æ‰€æœ‰é¡µé¢æ–‡æœ¬
        full_text = '\n\n'.join(all_text)
        
        # æ¸…ç†é‡å¤çš„ç©ºè¡Œ
        full_text = re.sub(r'\n\s*\n\s*\n+', '\n\n', full_text)
        
        # ä¿®å¤å¸¸è§çš„PDFæå–é—®é¢˜
        full_text = self._fix_common_pdf_issues(full_text)
        
        # æ·»åŠ æ–‡æ¡£ç»“æ„ä¿¡æ¯
        structure_info = self._add_structure_info(page_stats)
        
        return structure_info + '\n\n' + full_text
    
    def _fix_common_pdf_issues(self, text: str) -> str:
        """ä¿®å¤å¸¸è§çš„PDFæå–é—®é¢˜"""
        # ä¿®å¤è¢«åˆ†å‰²çš„å•è¯
        text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
        
        # ä¿®å¤è¢«åˆ†å‰²çš„å¥å­
        text = re.sub(r'(\w+)\s*\n\s*([a-z])', r'\1 \2', text)
        
        # ä¿®å¤ç‰¹æ®Šå­—ç¬¦
        text = unicodedata.normalize('NFKC', text)
        
        # ä¿®å¤æ•°å­—å’Œå•ä½
        text = re.sub(r'(\d+)\s+(\d+)', r'\1\2', text)  # ä¿®å¤è¢«åˆ†å‰²çš„æ•°å­—
        
        return text
    
    def _add_structure_info(self, page_stats: List[Dict[str, Any]]) -> str:
        """æ·»åŠ æ–‡æ¡£ç»“æ„ä¿¡æ¯"""
        total_pages = len(page_stats)
        high_quality_pages = sum(1 for p in page_stats if p['content_quality'] == 'high')
        has_abstract = any(p['has_abstract'] for p in page_stats)
        has_references = any(p['has_references'] for p in page_stats)
        
        structure_info = f"""# PDFæ–‡æ¡£ç»“æ„åˆ†æ
- æ€»é¡µæ•°: {total_pages}
- é«˜è´¨é‡é¡µé¢: {high_quality_pages} ({high_quality_pages/total_pages*100:.1f}%)
- åŒ…å«æ‘˜è¦: {'æ˜¯' if has_abstract else 'å¦'}
- åŒ…å«å‚è€ƒæ–‡çŒ®: {'æ˜¯' if has_references else 'å¦'}
- æå–æ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return structure_info

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("âŒ ä½¿ç”¨æ–¹æ³•: python pdf_to_txt_enhanced.py <PDFæ–‡ä»¶è·¯å¾„> [è¾“å‡ºæ–‡ä»¶è·¯å¾„]")
        print("ğŸ’¡ ç¤ºä¾‹:")
        print("   python pdf_to_txt_enhanced.py data/artemisinin_pcos.pdf")
        print("   python pdf_to_txt_enhanced.py data/artemisinin_pcos.pdf outputs/enhanced_text.txt")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    out_path = sys.argv[2] if len(sys.argv) > 2 else pdf_path.replace(".pdf", "_enhanced.txt")
    
    if not os.path.exists(pdf_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        sys.exit(1)
    
    # åˆ›å»ºé«˜ç²¾åº¦æå–å™¨
    extractor = EnhancedPDFExtractor()
    
    # æå–æ–‡æœ¬
    text = extractor.extract_text_from_pdf(pdf_path, out_path)
    
    if text:
        print(f"âœ… é«˜ç²¾åº¦æå–å®Œæˆ!")
        print(f"ğŸ“Š æå–æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {out_path}")
    else:
        print("âŒ æ–‡æœ¬æå–å¤±è´¥")

if __name__ == "__main__":
    main()
