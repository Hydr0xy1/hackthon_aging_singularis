#!/usr/bin/env python3
"""
ä¿®å¤å‚æ•°å¤„ç†çš„ç»ˆæç‰ˆæœ¬
"""

import sys
import os
import time
from pathlib import Path

def main(pdf_path):
    """è¿è¡Œå®Œæ•´pipeline"""
    print(f"ğŸš€ å¼€å§‹å¤„ç†: {pdf_path}")
    start_time = time.time()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path("outputs").mkdir(exist_ok=True)
    
    # ç®€åŒ–æ–‡ä»¶åï¼ˆé¿å…é•¿è·¯å¾„é—®é¢˜ï¼‰
    original_path = pdf_path
    if len(pdf_path) > 50:
        short_name = "data/artemisinin_pcos.pdf"
        if not os.path.exists(short_name) and os.path.exists(pdf_path):
            print(f"ğŸ“ å°†æ–‡ä»¶é‡å‘½åä¸ºçŸ­åç§°: {short_name}")
            os.rename(pdf_path, short_name)
            pdf_path = short_name
    
    # ç°åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ï¼ˆé¿å…åœ¨å‚æ•°æ£€æŸ¥å‰å¯¼å…¥å¯èƒ½å¤±è´¥çš„æ¨¡å—ï¼‰
    try:
        import fitz
        import re
        import csv
        import json
        import uuid
        from collections import Counter, defaultdict
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return
    
    class UltimateIMRaDExtractor:
        # è¿™é‡Œæ’å…¥ä¹‹å‰å®Œæ•´çš„ UltimateIMRaDExtractor ç±»ä»£ç 
        # ä¸ºäº†ç®€æ´ï¼Œæˆ‘åœ¨è¿™é‡Œçœç•¥äº†ç±»çš„å®Œæ•´ä»£ç ï¼Œä½†æ‚¨éœ€è¦å°†ä¹‹å‰çš„å†…å®¹å¤åˆ¶åˆ°è¿™é‡Œ
        
        def __init__(self):
            self.section_patterns = {
                "introduction": r"(?:^|\n)(?:\s*\d*\.*\s*Introduction|Background)",
                "methods": r"(?:^|\n)(?:\s*\d*\.*\s*(Materials and Methods|Methods|Experimental Procedures))",
                "results": r"(?:^|\n)(?:\s*\d*\.*\s*Results?)",
                "discussion": r"(?:^|\n)(?:\s*\d*\.*\s*(Discussion|Conclusion|Summary))",
            }
            
            self.cue_patterns = {
                "Hypothesis": [
                    r"\bwe hypothesi[sz]e\b", r"\bwe propose\b", r"\bthis study aims to\b",
                    r"\bwe expect\b", r"\bwe predict\b", r"\bit is hypothesized\b"
                ],
                "Experiment": [
                    r"\bwe conducted\b", r"\bwe performed\b", r"\bexperiments\b",
                    r"\bwe treated\b", r"\bmethods\b", r"\bexperimental\b",
                    r"\bwe used\b", r"\bwe measured\b"
                ],
                "Dataset": [
                    r"\bcohort\b", r"\bn\s*=\s*\d+", r"\bdata from\b",
                    r"\bpatients\b", r"\bsamples\b", r"\bdataset\b",
                    r"\bclinical data\b", r"\bobtained from\b"
                ],
                "Analysis": [
                    r"\bwe analyzed\b", r"\bstatistical analysis\b", r"\bp\s*[<â‰¤]\s*0\.\d+",
                    r"\bsignificant\b", r"\bdata demonstrate\b", r"\bwe calculated\b",
                    r"\bcorrelation\b", r"\bregression\b"
                ],
                "Conclusion": [
                    r"\bin conclusion\b", r"\bwe conclude\b", r"\bthese results suggest\b",
                    r"\bthis study shows\b", r"\bour findings\b", r"\bthese data indicate\b",
                    r"\boverall\b.*\bsuggest\b"
                ]
            }
            
            self.edge_rules = [
                ("Hypothesis", "Experiment", "hypothesis_to_experiment"),
                ("Experiment", "Dataset", "experiment_to_dataset"), 
                ("Dataset", "Analysis", "dataset_to_analysis"),
                ("Analysis", "Conclusion", "analysis_to_conclusion"),
            ]
        
        def extract_text_from_pdf(self, pdf_path):
            """ä»PDFæå–æ–‡æœ¬"""
            print(f"ğŸ“„ ä» {os.path.basename(pdf_path)} æå–æ–‡æœ¬...")
            try:
                doc = fitz.open(pdf_path)
                text = ""
                for page_num, page in enumerate(doc):
                    page_text = page.get_text("text")
                    # æ¸…ç†æ–‡æœ¬ï¼šç§»é™¤é¡µç å’ŒçŸ­è¡Œ
                    lines = []
                    for line in page_text.split("\n"):
                        line = line.strip()
                        # è¿‡æ»¤æ‰é¡µç å’Œå¤ªçŸ­çš„è¡Œ
                        if (not re.match(r"^\s*\d+\s*$", line) and 
                            len(line) > 15 and  # å¢åŠ æœ€å°é•¿åº¦
                            not line.isupper() and  # è¿‡æ»¤å…¨å¤§å†™çš„è¡Œ
                            not re.match(r'^\s*[A-Z\s]+\s*$', line)):  # è¿‡æ»¤åªæœ‰å¤§å†™å­—æ¯çš„è¡Œ
                            lines.append(line)
                    text += " ".join(lines) + "\n\n"
                doc.close()
                return text
            except Exception as e:
                print(f"âŒ PDFæå–é”™è¯¯: {e}")
                return ""
        
        def sentence_segmentation(self, text):
            """å¥å­åˆ†å‰² - ä½¿ç”¨ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•"""
            # å…ˆæŒ‰æ®µè½åˆ†å‰²
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            
            sentences = []
            for paragraph in paragraphs:
                # åœ¨æ®µè½å†…æŒ‰å¥å­ç»“æŸç¬¦åˆ†å‰²
                paragraph_sentences = re.split(r'(?<=[.!?])\s+', paragraph)
                for sent in paragraph_sentences:
                    sent = sent.strip()
                    if len(sent) > 20:  # åªä¿ç•™è¶³å¤Ÿé•¿çš„å¥å­
                        sentences.append(sent)
            
            return sentences
        
        def gen_id(self, prefix):
            """ç”Ÿæˆå”¯ä¸€ID"""
            return f"{prefix}_{uuid.uuid4().hex[:6]}"
        
        def create_node(self, node_type, text, section, confidence=0.8, evidence=""):
            """åˆ›å»ºèŠ‚ç‚¹"""
            return {
                "id": self.gen_id(node_type[:3].upper()),
                "type": node_type,
                "text": text[:350],  # æˆªæ–­é•¿æ–‡æœ¬ä½†ä¿ç•™æ›´å¤šå†…å®¹
                "section": section,
                "confidence": confidence,
                "evidence": evidence,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }
        
        def segment_imrad(self, text):
            """IMRaDåˆ†æ®µ"""
            indices = []
            for name, pattern in self.section_patterns.items():
                matches = list(re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE))
                if matches:
                    indices.append((matches[0].start(), name))
            
            if not indices:
                print("âš ï¸  æœªæ£€æµ‹åˆ°æ ‡å‡†IMRaDç« èŠ‚ï¼Œä½¿ç”¨å…¨æ–‡å¤„ç†")
                return {"full_text": text}

            indices.sort()
            sections = {}
            
            for i, (start, name) in enumerate(indices):
                # ç»“æŸä½ç½®æ˜¯ä¸‹ä¸€ä¸ªsectionçš„å¼€å§‹ï¼Œæˆ–è€…æ˜¯æ–‡æœ¬ç»“å°¾
                end = indices[i + 1][0] if i + 1 < len(indices) else len(text)
                section_content = text[start:end].strip()
                
                # ç§»é™¤ç« èŠ‚æ ‡é¢˜è¡Œ
                lines = section_content.split('\n')
                if len(lines) > 1:
                    # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜ï¼‰
                    section_content = '\n'.join(lines[1:]).strip()
                
                sections[name] = section_content
            
            return sections
        
        def extract_nodes_from_section(self, section_name, text):
            """ä»ç« èŠ‚æ–‡æœ¬æå–èŠ‚ç‚¹"""
            sentences = self.sentence_segmentation(text)
            nodes = []
            
            for sentence in sentences:
                matched = False
                for node_type, patterns in self.cue_patterns.items():
                    for pattern in patterns:
                        if re.search(pattern, sentence, re.IGNORECASE):
                            nodes.append(self.create_node(
                                node_type, sentence, section_name,
                                evidence=f"pattern:{pattern}"
                            ))
                            matched = True
                            break
                    if matched:
                        break
            
            return nodes
        
        def extract_imrad_from_text(self, text):
            """ä»å®Œæ•´æ–‡æœ¬æå–IMRaDèŠ‚ç‚¹"""
            sections = self.segment_imrad(text)
            all_nodes = []
            
            print(f"ğŸ“‘ æ£€æµ‹åˆ° {len(sections)} ä¸ªç« èŠ‚: {list(sections.keys())}")
            
            for section_name, section_text in sections.items():
                if len(section_text.strip()) < 100:  # è·³è¿‡å¤ªçŸ­çš„ç« èŠ‚
                    continue
                    
                nodes = self.extract_nodes_from_section(section_name, section_text)
                print(f"   ğŸ“ {section_name}: æå–äº† {len(nodes)} ä¸ªèŠ‚ç‚¹")
                all_nodes.extend(nodes)
            
            # ç»Ÿè®¡èŠ‚ç‚¹ç±»å‹
            if all_nodes:
                node_types = Counter([node["type"] for node in all_nodes])
                print(f"ğŸ“Š èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ: {dict(node_types)}")
            else:
                print("âš ï¸  æœªæå–åˆ°ä»»ä½•èŠ‚ç‚¹ï¼Œå°†æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å¥å­")
                # æ˜¾ç¤ºä¸€äº›å¥å­ç”¨äºè°ƒè¯•
                sentences = self.sentence_segmentation(text)
                for i, sent in enumerate(sentences[:5]):
                    print(f"   ç¤ºä¾‹ {i+1}: {sent[:80]}...")
            
            return all_nodes
        
        def build_edges(self, nodes):
            """æ„å»ºè¾¹å…³ç³»"""
            edges = []
            node_ids_by_type = defaultdict(list)
            
            for node in nodes:
                node_ids_by_type[node['type']].append(node['id'])
            
            edge_counts = {}
            for src_type, tgt_type, rel_type in self.edge_rules:
                if src_type in node_ids_by_type and tgt_type in node_ids_by_type:
                    count = 0
                    for src_id in node_ids_by_type[src_type]:
                        for tgt_id in node_ids_by_type[tgt_type]:
                            edges.append({
                                "start": src_id,
                                "end": tgt_id,
                                "type": rel_type,
                                "confidence": 0.7
                            })
                            count += 1
                    edge_counts[rel_type] = count
                    print(f"  ğŸ”— {rel_type}: {count} æ¡è¾¹")
                else:
                    print(f"  âš ï¸  è·³è¿‡ {rel_type}: ç¼ºå°‘ {src_type} æˆ– {tgt_type}")
            
            return edges
        
        def export_to_csv(self, nodes, edges, base_name):
            """å¯¼å‡ºä¸ºCSVæ–‡ä»¶"""
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            Path("outputs").mkdir(exist_ok=True)
            
            # èŠ‚ç‚¹CSV
            if nodes:
                nodes_file = f"{base_name}_nodes.csv"
                with open(nodes_file, 'w', newline='', encoding='utf-8') as f:
                    fieldnames = ['id', 'type', 'text', 'section', 'confidence', 'evidence', 'timestamp']
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    for node in nodes:
                        # ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨
                        row = {field: node.get(field, '') for field in fieldnames}
                        writer.writerow(row)
                print(f"  ğŸ’¾ èŠ‚ç‚¹ä¿å­˜: {nodes_file}")
            
            # è¾¹CSV  
            if edges:
                edges_file = f"{base_name}_edges.csv"
                with open(edges_file, 'w', newline='', encoding='utf-8') as f:
                    fieldnames = ['start', 'end', 'type', 'confidence']
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    for edge in edges:
                        writer.writerow(edge)
                print(f"  ğŸ’¾ è¾¹ä¿å­˜: {edges_file}")
        
        def create_simple_visualization(self, nodes, edges, output_file):
            """åˆ›å»ºç®€å•çš„HTMLå¯è§†åŒ–"""
            html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>IMRaD Knowledge Graph</title>
        <meta charset="utf-8">
        <style>
            body { 
                font-family: 'Segoe UI', Arial, sans-serif; 
                margin: 20px; 
                background: #f5f5f5;
            }
            .container {
                max-width: 1200px;
                margin: 0 auto;
                background: white;
                padding: 20px;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            h1 { 
                color: #2c3e50; 
                border-bottom: 3px solid #3498db;
                padding-bottom: 10px;
            }
            .stats {
                background: #ecf0f1;
                padding: 15px;
                border-radius: 5px;
                margin: 20px 0;
            }
            .node { 
                margin: 10px 0; 
                padding: 15px; 
                border-radius: 8px; 
                color: white; 
                border-left: 5px solid rgba(0,0,0,0.2);
                box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            }
            .hypothesis { background: #e67e22; }
            .experiment { background: #3498db; }
            .dataset { background: #1abc9c; }
            .analysis { background: #9b59b6; }
            .conclusion { background: #e74c3c; }
            .edge { 
                margin: 8px 0; 
                padding: 10px; 
                background: #f8f9fa;
                border-left: 4px solid #34495e;
                border-radius: 4px;
            }
            .section {
                background: #2c3e50;
                color: white;
                padding: 10px 15px;
                margin: 20px 0 10px 0;
                border-radius: 5px;
                font-weight: bold;
            }
            .node-type {
                font-weight: bold;
                font-size: 1.1em;
            }
            .node-text {
                margin: 8px 0;
                line-height: 1.4;
            }
            .node-meta {
                font-size: 0.9em;
                opacity: 0.8;
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ“Š IMRaD Knowledge Graph</h1>
            
            <div class="stats">
                <strong>æå–ç»Ÿè®¡:</strong><br>
                èŠ‚ç‚¹æ€»æ•°: %NODE_COUNT% | è¾¹å…³ç³»æ€»æ•°: %EDGE_COUNT%<br>
                å¤„ç†æ—¶é—´: %TIMESTAMP%
            </div>
            
            <h2>ğŸ”— è¾¹å…³ç³»</h2>
            %EDGES%
            
            <h2>ğŸ“ æå–çš„èŠ‚ç‚¹</h2>
            %NODES%
        </div>
    </body>
    </html>
            """
            
            # æŒ‰ç« èŠ‚åˆ†ç»„èŠ‚ç‚¹
            nodes_by_section = defaultdict(list)
            for node in nodes:
                nodes_by_section[node['section']].append(node)
            
            # ç”ŸæˆèŠ‚ç‚¹HTML
            nodes_html = ""
            for section_name, section_nodes in nodes_by_section.items():
                nodes_html += f'<div class="section">ğŸ“ {section_name.upper()} ç« èŠ‚</div>'
                for node in section_nodes:
                    nodes_html += f"""
                    <div class="node {node['type'].lower()}">
                        <div class="node-type">{node['type']}</div>
                        <div class="node-text">{node['text']}</div>
                        <div class="node-meta">
                            ID: {node['id']} | ç½®ä¿¡åº¦: {node.get('confidence', 'N/A')} | 
                            è¯æ®: {node.get('evidence', 'N/A')}
                        </div>
                    </div>
                    """
            
            # ç”Ÿæˆè¾¹HTML
            edges_html = ""
            for edge in edges:
                edges_html += f"""
                <div class="edge">
                    <strong>{edge['start']}</strong> â†’ 
                    <strong>{edge['end']}</strong> 
                    <small>({edge['type']} | ç½®ä¿¡åº¦: {edge.get('confidence', 'N/A')})</small>
                </div>
                """
            
            # æ›¿æ¢æ¨¡æ¿ä¸­çš„å ä½ç¬¦
            html_content = html_content.replace("%NODE_COUNT%", str(len(nodes))) \
                                      .replace("%EDGE_COUNT%", str(len(edges))) \
                                      .replace("%TIMESTAMP%", time.strftime("%Y-%m-%d %H:%M:%S")) \
                                      .replace("%NODES%", nodes_html) \
                                      .replace("%EDGES%", edges_html)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"  ğŸŒ HTMLå¯è§†åŒ–: {output_file}")

    extractor = UltimateIMRaDExtractor()
    
    try:
        # æ­¥éª¤1: æå–æ–‡æœ¬
        text = extractor.extract_text_from_pdf(pdf_path)
        if not text or len(text) < 100:
            print("âŒ æ–‡æœ¬æå–å¤±è´¥æˆ–æ–‡æœ¬è¿‡çŸ­")
            return
        
        print(f"âœ… æˆåŠŸæå–æ–‡æœ¬ ({len(text)} å­—ç¬¦)")
        
        # æ­¥éª¤2: æå–èŠ‚ç‚¹
        print("\nğŸ” æ­£åœ¨æå–IMRaDèŠ‚ç‚¹...")
        nodes = extractor.extract_imrad_from_text(text)
        
        if not nodes:
            print("âŒ æœªæå–åˆ°ä»»ä½•èŠ‚ç‚¹")
            print("ğŸ’¡ å¯èƒ½çš„åŸå› :")
            print("   - PDFå†…å®¹ä¸IMRaDç»“æ„ä¸åŒ¹é…")
            print("   - æ­£åˆ™æ¨¡å¼éœ€è¦è°ƒæ•´")
            print("   - PDFæ˜¯æ‰«æä»¶æˆ–æ ¼å¼ç‰¹æ®Š")
            return
        
        print(f"âœ… æˆåŠŸæå– {len(nodes)} ä¸ªèŠ‚ç‚¹")
        
        # æ­¥éª¤3: æ„å»ºè¾¹
        print("\nğŸ”— æ­£åœ¨æ„å»ºè¾¹å…³ç³»...")
        edges = extractor.build_edges(nodes)
        print(f"âœ… æˆåŠŸæ„å»º {len(edges)} æ¡è¾¹")
        
        # æ­¥éª¤4: ä¿å­˜ç»“æœ
        print("\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
        base_name = f"outputs/{Path(pdf_path).stem}"
        
        extractor.export_to_csv(nodes, edges, base_name)
        extractor.create_simple_visualization(nodes, edges, f"{base_name}_graph.html")
        
        elapsed_time = time.time() - start_time
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ! ç”¨æ—¶ {elapsed_time:.2f} ç§’")
        print(f"ğŸ“Š æœ€ç»ˆç»“æœ: {len(nodes)} ä¸ªèŠ‚ç‚¹, {len(edges)} æ¡è¾¹")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - {base_name}_nodes.csv")
        print(f"   - {base_name}_edges.csv") 
        print(f"   - {base_name}_graph.html")
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("âŒ ä½¿ç”¨æ–¹æ³•: python run_ultimate_fixed.py <PDFæ–‡ä»¶è·¯å¾„>")
        print("ğŸ’¡ ç¤ºä¾‹:")
        print('   python run_ultimate_fixed.py "data/Artemisinins ameliorate polycystic ovarian syndrome by mediating LONP1-CYP11A1 interaction.pdf"')
        print("   æˆ–è€…: python run_ultimate_fixed.py data/artemisinin_pcos.pdf")
        sys.exit(1)
    
    pdf_file = sys.argv[1]
    if not os.path.exists(pdf_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        sys.exit(1)
    
    main(pdf_file)